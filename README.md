# CommonCrawl
#  Contrastive Entity & Relation Analysis

##  Description
Ce projet impl√©mente une **analyse contrastive** pour d√©tecter et comparer les entit√©s nomm√©es ainsi que leurs relations dans un corpus textuel.  
Il exploite des donn√©es issues de **Common Crawl** et s‚Äôappuie sur des annotations pour entra√Æner et √©valuer un mod√®le de classification **relation-rich** vs **relation-poor**.

##  Structure du d√©p√¥t

‚îú‚îÄ‚îÄ analysis_results_with_pos.jsonl # R√©sultats d'analyse enrichis avec POS tagging
‚îú‚îÄ‚îÄ COMMONcrawl.ipynb # Notebook d'analyse et d'exp√©rimentation
‚îú‚îÄ‚îÄ contrastive_analysis_report.json # Rapport complet sur les statistiques
‚îú‚îÄ‚îÄ contrastive_learning_analysis.png # Visualisation du processus d'analyse
‚îú‚îÄ‚îÄ labeled_results.jsonl # Donn√©es annot√©es manuellement
‚îú‚îÄ‚îÄ sample_wet_subset.jsonl # √âchantillon Common Crawl utilis√©
‚îú‚îÄ‚îÄ README.md # Documentation du projet

## üìë Contenu cl√©
- **contrastive_analysis_report.json**  
  R√©sum√© statistique du corpus :
  - 17 documents analys√©s
  - 93 entit√©s d√©tect√©es (70 uniques)
  - Distribution `relation-rich` : 13 / `relation-poor` : 4
  - Entit√©s les plus fr√©quentes : Fairbanks, Alaska, ParkWhiz, Knotts Berry Farm
  - Recommandations d‚Äôentra√Ænement :  
    - `min_common_entities = 1`  
    - `batch_size = 8`  
    - `epochs = 5`  
    - `balance_ratio = 1.0`

- **analysis_results_with_pos.jsonl**  
  R√©sultats enrichis avec des **tags morphosyntaxiques (POS)** pour chaque entit√©.

- **labeled_results.jsonl**  
  √âtiquetage manuel des relations entre entit√©s.

- **sample_wet_subset.jsonl**  
  Sous-ensemble du corpus **Common Crawl WET**.

- **COMMONcrawl.ipynb**  
  Notebook Jupyter regroupant :
  - Pr√©traitement des donn√©es
  - Extraction des entit√©s
  - Analyse des relations
  - Visualisations

- **contrastive_learning_analysis.png**  
  Illustration visuelle du pipeline d‚Äôanalyse contrastive.

## ‚öôÔ∏è Installation
```bash
# Cloner le repo
git clone https://github.com/username/nom-du-repo.git
cd nom-du-repo

# Cr√©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate
```

Utilisation

Explorer le notebook
Ouvrir COMMONcrawl.ipynb dans Jupyter pour reproduire l‚Äôanalyse.

Analyser les rapports
Charger contrastive_analysis_report.json pour explorer les statistiques globales.

Entra√Æner un mod√®le contrastif
Utiliser les recommandations fournies dans le rapport pour d√©finir vos hyperparam√®tres.

 Exemple de statistiques

Total documents : 17

Moyenne d'entit√©s/document : 5.47

Classement entit√©s fr√©quentes :

Fairbanks (5)

Alaska (5)

ParkWhiz (4)

Knotts Berry Farm (4)

Aper√ßu du pipeline
1. Installation et configuration des d√©pendances

Plusieurs cellules installent les biblioth√®ques n√©cessaires :

NLP & embeddings :

sentence-transformers, transformers ‚Üí mod√®les de type BERT, RoBERTa, etc., pour embeddings et classification.

flair, spacy ‚Üí NER, POS tagging.

fasttext, langdetect, pycld3 ‚Üí d√©tection de langue.

Parsing HTML & WARC/WET :

boilerpy3, justext, beautifulsoup4 ‚Üí extraction du texte brut en supprimant le bruit HTML.

warcio, warc ‚Üí lecture des fichiers WARC/WET de Common Crawl.

Utilitaires :

datasets ‚Üí chargement d‚Äô√©chantillons Hugging Face.

boto3, botocore ‚Üí acc√®s √† S3 (optionnel pour t√©l√©charger Common Crawl directement).

tqdm ‚Üí barres de progression.

2. Ingestion & pr√©traitement des donn√©es

Source : fichiers WET (Web Extracted Text) de Common Crawl.

Alternative : chargement d‚Äôun petit sous-ensemble d√©j√† pr√™t via datasets sur Hugging Face (√©vite de t√©l√©charger plusieurs Go).

√âtapes de pr√©traitement :

Lecture ligne par ligne (JSONL).

Nettoyage du HTML avec boilerpy3 ou justext.

D√©tection de langue ‚Üí garder uniquement une langue cible (ex. anglais).

Suppression des documents trop courts (MIN_WORDS) ou avec faible diversit√© lexicale (MIN_UNIQUE_RATIO).

3. Analyse linguistique

NER (Named Entity Recognition) :
Utilisation de spaCy ou flair pour extraire PERSON, ORG, LOC, etc.
Exemple : "Barack Obama visited Paris" ‚Üí PERSON=Barack Obama, LOC=Paris.

POS tagging (Part-of-Speech) :
D√©tection des verbes, noms, adjectifs, etc. pour analyser les structures grammaticales.
Sert notamment √† trouver des co-occurrences entit√©s + actions.

4. Labellisation hybride (Weak Supervision)

Heuristiques :

Score bas√© sur densit√© d‚Äôentit√©s nomm√©es.

Pond√©ration si entit√©s et verbes apparaissent ensemble dans certaines structures.

Zero-shot classification :

Utilisation de mod√®les comme facebook/bart-large-mnli pour classer les documents dans des cat√©gories sans entra√Ænement sp√©cifique.

Exemple : prompt ‚Üí "Ce document parle-t-il de politique, sport, technologie ?"

5. Apprentissage auto-supervis√© (Contrastive Learning)

G√©n√©ration de paires :

Positives : deux documents avec un certain nombre d‚Äôentit√©s en commun.

N√©gatives : documents sans entit√©s partag√©es.

Entra√Ænement :

Utilisation de mod√®les type sentence-transformers pour apprendre un espace vectoriel o√π les documents similaires (positifs) sont proches, et les diff√©rents (n√©gatifs) sont √©loign√©s.

6. Sorties attendues

Fichiers JSONL √† chaque √©tape :

Donn√©es brutes nettoy√©es.

R√©sultats d‚Äôanalyse (entit√©s, POS tags).

R√©sultats labellis√©s (weak supervision).

Embeddings finaux apr√®s apprentissage contrastif.

